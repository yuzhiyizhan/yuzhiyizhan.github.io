---
layout: post
title: "使用PaddleOCR训练自己的识别验证码的OCR"
date:   2023-02-07
tags: [深度学习]
comments: true
author: 0基础的菜狗
---

# 注意事项 #

**暂时只在windows环境下训练成功**

**由于PaddleOCR读取图片用的库是opencv，所以包括图片在内的所有路径一定不能用中文**

**如果要训练中文需要自己准备数据集和对应的字符集**

## 1. 训练场地的选择 ##
第一种(推荐): 使用飞浆自己的平台[飞浆AI Studio](https://aistudio.baidu.com/aistudio/index)坑非常少而且每天能白嫖GPU

第二种: 本地 坑比较多但是幸好官方文档讲的比较详细 [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.5/README_ch.md)

## 2. 数据集的准备 ##
### 需要准备数据集的格式如下: ###

    |--train  //训练集
    
    |--test   //测试集
    
    |--train.txt     //训练集标签
    
    |--test.txt      //测试集标签

自己的数据集往往格式不是这么工整所以需要自己处理成这种格式

### 例如一张图片文件名如下: ###

abcd_md5.jpg

abcd为图片的标签,md5是随意的目的是为了区分开标签相同的图片

把全部图片放到同一目录下

    |--dataset
    
    |  |--abcd_md5.jpg
    
    |  |--adcd_md6.jpg
    
    |  |--***

### 编写如下脚本 ###
```
import os
import re
import time
import random
import shutil
import hashlib

from loguru import logger


class Division_Dateset(object):

    def __init__(self, **kwargs):
        self.my_dict = []
        self.data_path = kwargs.get('data_path', 'shangbiao_dataset')
        self.number = kwargs.get('number', 0.95)

    def MD5(self, strings):
        strings = str(strings)
        string = hashlib.md5(bytes(strings, encoding='utf-8'))
        return string.hexdigest()

    def inspect_path(self):
        self.dataset_list = [os.path.join(os.path.join(os.getcwd(), self.data_path), i) for i in
                             os.listdir(self.data_path)]
        self.train_path = os.path.join(os.getcwd(), 'train')
        self.test_path = os.path.join(os.getcwd(), 'test')

        for i in [self.train_path, self.test_path]:
            if not os.path.exists(i):
                os.makedirs(i)

    def get_len(self):
        len_number = len(self.dataset_list)
        # 控制训练集和测试集的比例
        self.inspect_dataset_len = int(len_number * self.number)

        random.shuffle(self.dataset_list)

    def main(self):
        self.inspect_path()
        self.get_len()

        # 训练集
        for i in self.dataset_list[:self.inspect_dataset_len:]:
            path, jpg = os.path.split(i)
            name, shuffix = os.path.splitext(jpg)
            label = re.split('_', jpg)[0]
            # label = jpg[:4:]
            logger.debug(label)
            [self.my_dict.append(i) for i in label]
            new_name = self.MD5(f'{path}{jpg}{str(time.time())}')
            with open('train.txt', 'a', encoding='utf-8') as f:
                f.write(f'train/{new_name}{shuffix}\t{label}\n')
            shutil.copy(i, os.path.join(self.train_path, new_name + shuffix))
            # break

        # 测试集
        for i in self.dataset_list[self.inspect_dataset_len::]:
            path, jpg = os.path.split(i)
            name, shuffix = os.path.splitext(jpg)
            label = re.split('_', jpg)[0]
            # label = jpg[:4:]
            logger.debug(label)
            [self.my_dict.append(i) for i in label]
            new_name = self.MD5(f'{path}{jpg}{str(time.time())}')
            with open('test.txt', 'a', encoding='utf-8') as f:
                f.write(f'test/{new_name}{shuffix}\t{label}\n')
            shutil.copy(i, os.path.join(self.test_path, new_name + shuffix))

        self.my_dict.sort()
        with open('my_dict.txt', 'a', encoding='utf-8') as f:
            [f.write(f'{i}\n') for i in set(self.my_dict)]


if __name__ == '__main__':
    # data_path 数据集的目录
    # number 划分的比例
    Division_Dateset(data_path='label').main()
```

把文件和脚本放到同一目录，运行脚本即可，代码不长，可以阅读一下，格式就是这个格式

注意：该脚本只能处理英文，中文的没写因为没碰上需求，主要目的是处理成上面的数据集格式即可

需要注意的是弄中文的话还需要准备一个txt文件，里面放的你的数据集里出现的所有字符，一行一个字，类似这样

屌

你

...

## 3. 装环境 ##

先下载PaddleOCR [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR)

这里我以手动下载PaddleOCR.zip 为例

如果你是在飞浆AI Studio上面弄的话参考这个最新教程[【官方】十分钟完成 PP-OCRv3 识别全流程实战](https://aistudio.baidu.com/aistudio/projectdetail/3916206)

基本无坑

### 下面是在本地的环境安装 ###

1. 按照官方的教程创建一个虚拟环境并进入到虚拟环境[运行环境准备](https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.5/doc/doc_ch/environment.md)

2. 把下载的PaddleOCR解压并**进入**,使用飞浆AI Studio的上传压缩包并打开一个终端解压

3. 进入[飞浆官网](https://www.paddlepaddle.org.cn/)根据自己的本地环境有无GPU安装paddlepaddle

4. 安装PaddleOCR的环境

```
pip install -r requirements.txt -i https://mirror.baidu.com/pypi/simple
```

注意：这时候你应该装不上，如果装上了当然最好 这时你只需要复制错误找百度即可，太简单这里就跳了

5. 写个小脚本测试一下，下面脚本放到PaddleOCR目录下

```
from paddleocr import PaddleOCR

ocr = PaddleOCR()  # need to run only once to download and load model into memory
img_path = r'.\doc\imgs_words\en\word_1.png'
result = ocr.ocr(img_path, det=False)
for line in result:
    print(line)
```

至此基本完成了环境的安装

## 4. 下载预训练模型并解压 ##

由于是OCR任务所以下载识别相关的模型[中英文超轻量PP-OCRv3模型](https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_rec_train.tar)

在当前目录下新建一个pretrain_models 文件夹，把解压后的模型放进去

此时你的pretrain_models文件夹应该结构如下:

    |--pretrain_models
    
    |   |--ch_PP-OCRv3_rec_train
    
    |   |   |--best_accuracy.pdparams


后面百度出好的就用更好的，一直白嫖就完事

## 5. 修改配置文件 ##

注意：这一步非常关键，因为最多坑的地方就是这里

1. 先在PaddleOCR的目录下新建文件夹 train_data

2. 把之前准备好的数据集放入这个文件夹

3. 此时你的train_data文件夹应该如下:

   |--train_data
    
    |   |--train
    
    |   |--test
    
    |   |--train.txt
    
    |   |--text.txt


4. configs/rec/PP-OCRv3/ch_PP-OCRv3_rec.yml 在这个目录下修改自己的配置

5. 这里说下你应该要改的地方

```
Train:
  dataset:
    name: SimpleDataSet
    data_dir: ./train_data/
    ext_op_transform_idx: 1
    label_file_list:
    - ./train_data/train.txt
    transforms:
    - DecodeImage:
        img_mode: BGR
        channel_first: false
    - RecConAug:
        prob: 0.5
        ext_data_num: 2
        image_shape: [48, 320, 3]
    - RecAug:
    - MultiLabelEncode:
    - RecResizeImg:
        image_shape: [3, 48, 320]
    - KeepKeys:
        keep_keys:
        - image
        - label_ctc
        - label_sar
        - length
        - valid_ratio
  loader:
    shuffle: true
    batch_size_per_card: 128
    drop_last: true
    num_workers: 0
Eval:
  dataset:
    name: SimpleDataSet
    data_dir: ./train_data
    label_file_list:
    - ./train_data/test.txt
    transforms:
    - DecodeImage:
        img_mode: BGR
        channel_first: false
    - MultiLabelEncode:
    - RecResizeImg:
        image_shape: [3, 48, 320]
    - KeepKeys:
        keep_keys:
        - image
        - label_ctc
        - label_sar
        - length
        - valid_ratio
  loader:
    shuffle: false
    drop_last: false
    batch_size_per_card: 128
    num_workers: 0
```

特别注意这个num_workers参数 0的意思的单线程 根据自己的CPU核心数来设置该参数，其他的抄我的一般也没问题

如果还有问题应该就是image_shape参数 比自己数据集要大 宽度320有一次听百度飞浆直播时听到的，这个数比较好且默认就是320，如果你的图片比这还长就需要调整

batch_size_per_card参数 一次放多少图片

6. 接下来是全局参数，参考我的

```
Global:
  debug: false
  use_gpu: false
  epoch_num: 500
  log_smooth_window: 20
  print_batch_step: 10
  save_model_dir: ./output/rec_ppocr_v3
  save_epoch_step: 3
  eval_batch_step: [0, 2000]
  cal_metric_during_train: true
  pretrained_model:./pretrain_models/ch_PP-OCRv3_rec_train/best_accuracy_new
  checkpoints: 
  save_inference_dir:
  use_visualdl: false
  infer_img: doc/imgs_words/ch/word_1.jpg
  character_dict_path: ppocr/utils/ppocr_keys_v1.txt
  max_text_length: &max_text_length 25
  infer_mode: false
  use_space_char: true
  distributed: true
  save_res_path: ./output/rec/predicts_ppocrv3.txt
```

几个参数见名知意

use_gpu 是否使用gpu

epoch_num 训练步数

max_text_length 标签最大长度

character_dict_path  这个参数就是数据集准备时需要你生成的txt，数据集上的字，里面都必须要有，如果你的数据集是英文和我的配置一样即可

pretrained_model  下面会介绍这个参数从哪来

其他参数查阅官方文档，一般就改这几个

## 6. 将Student模型的参数提取出 ##

编写下面脚本

```
import paddle
params = paddle.load('./pretrain_models/ch_PP-OCRv3_rec_train/best_accuracy' + '.pdparams')
new_state_dict = {}
for k1 in params.keys():
    if 'Student.' in k1:
        new_state_dict[k1.replace('Student.','')] = params[k1]
        # print(k1)
paddle.save(new_state_dict, './pretrain_models/ch_PP-OCRv3_rec_train/best_accuracy'+'_new.pdparams')
```

如果你用的不是ch_PP-OCRv3 需要自行修改一下

上面的pretrained_model参数，就是用的这个模型

## 7. 开始训练 ##

```
python tools/train.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec.yml
```

## 8. 评估模型 ##

修改配置文件

```
Global:
  checkpoints: ./output/rec_ppocr_v3/best_accuracy
  pretrained_model: ./output/rec_ppocr_v3/best_accuracy
  save_inference_dir: ./inference/ch_PP-OCRv3_rec/
```

这个checkpoints参数的意思是检查点 后面的意思是在评估集上最好的模型

这个pretrained_model参数 为预测模型

这个save_inference_dir参数 保存的位置

开始评估

不用GPU

```
python -m paddle.distributed.launch tools/eval.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec.yml
```

-c 参数就是指配置文件

用GPU

```
python3 -m paddle.distributed.launch --gpus '0' tools/eval.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec.yml
```

## 9. 测试单张 ##

现在我假设你的test文件夹里有这么一张图片 abcd_md5.jpg

那么测试单张图片的命令如下:

```
python tools/infer_rec.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec.yml -o Global.infer_img=train_data/test/abcd_md5.jpg
```

测试一个文件夹

```
python tools/infer_rec.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec.yml -o Global.infer_img=train_data/test/
```

## 10. 导出模型 ##

```
python tools/export_model.py -c configs/rec/PP-OCRv3/ch_PP-OCRv3_rec.yml
```

## 11. 使用导出的模型预测 ##

```
python tools/infer/predict_rec.py --image_dir="./train_data/test/abcd_md5.jpg" --rec_model_dir=./inference/ch_PP-OCRv3_rec/ --rec_char_dict_path=ppocr/utils/ppocr_keys_v1.txt
```

image_dir 参数为你要预测的图片

rec_model_dir 导出的模型路径

rec_char_dict_path 准备数据集时生成的有对应关系的字典

## 12. 部署 ##

将以下文件取出来:

      |--inference
      
      |--ppocr
      
      |--ppstructure
      
      |--tools
      
      |  |--paddleocr

服务端代码

```
import base64

import cv2
import numpy as np
from sanic import Sanic
from sanic.response import json

from paddleocr import PaddleOCR

app = Sanic(__name__)

ocr = PaddleOCR(
    rec_char_dict_path='ppocr/utils/ppocr_keys_v1.txt',
    rec_image_shape='3, 48, 320',
    rec_model_dir='./inference/ch_PP-OCRv3_rec/',
    use_gpu=False,
)  # need to run only once to download and load model into memory


@app.route("/predict", methods=["POST"])
async def data_route(request):
    img_base = request.form.get('img')
    img_byte = base64.b64decode(img_base.encode())

    img = cv2.imdecode(np.array(bytearray(img_byte), dtype='uint8'), cv2.IMREAD_UNCHANGED)
    result = ocr.ocr(img, det=False)
    # result = predict_img(img_byte)
    if result:
        return json({"result": result[0][0], "status": 200}, ensure_ascii=False, status=200)
    else:
        json({"result": False, "status": 400}, ensure_ascii=False, status=400)


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True, access_log=True, auto_reload=True, workers=1)

```

客户端代码

```
import time
import base64

import requests
from loguru import logger

s = time.time()

with open('abcd_md5.jpg', "rb") as fp:
    img = fp.read()
r = requests.post("http://127.0.0.1:5000/predict", data={
    "img": base64.b64encode(img).decode()})
logger.success(r.json())

logger.debug("耗时：{}s".format("%.2f" % (time.time() - s)))

```
服务端的代码需要指定模型和字典文件

注意：遇到参数不对的报错，删掉源文件后面的logger即可
